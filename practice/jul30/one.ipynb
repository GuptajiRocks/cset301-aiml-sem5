{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e003b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba697e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ariha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ariha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60071ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...  partisan\n",
      "1  VIDEO - #Obamacare:  Full of Higher Costs and ...  partisan\n",
      "2  Please join me today in remembering our fallen...   neutral\n",
      "3  RT @SenatorLeahy: 1st step toward Senate debat...   neutral\n",
      "4  .@amazon delivery #drones show need to update ...  partisan\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\\\train.tsv\", sep=\"\\t\", encoding=\"latin1\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd3335e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs. Cleaned Text:\n",
      "                                                text  \\\n",
      "0  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...   \n",
      "1  VIDEO - #Obamacare:  Full of Higher Costs and ...   \n",
      "2  Please join me today in remembering our fallen...   \n",
      "3  RT @SenatorLeahy: 1st step toward Senate debat...   \n",
      "4  .@amazon delivery #drones show need to update ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                          rt rep trey radel r slams  \n",
      "1            video full higher costs broken promises  \n",
      "2  please join today remembering fallen heroes ho...  \n",
      "3  rt st step toward senate debate leahycrapo bil...  \n",
      "4  delivery show need update law promote protect ...  \n"
     ]
    }
   ],
   "source": [
    "# Set of English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs, @mentions, and #hashtags\n",
    "    text = re.sub(r'http\\S+|www\\S+|@\\w+|#\\w+', '', text)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize (split into words)\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Rejoin words into a single string\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nOriginal vs. Cleaned Text:\")\n",
    "print(df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e597b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'].to_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53d5b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the TF-IDF matrix: (5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df['cleaned_text']\n",
    "y = df['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "print(f\"\\nShape of the TF-IDF matrix: {X_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a08f068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.7640\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.77      0.96      0.86       739\n",
      "    partisan       0.66      0.20      0.31       261\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.72      0.58      0.58      1000\n",
      "weighted avg       0.74      0.76      0.71      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=78)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9d36ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message: 'Higher costs are bad'\n",
      "Predicted Label: partisan\n",
      "\n",
      "Message: 'The committee will hold a hearing tomorrow at 10 AM to discuss the new transportation bill.'\n",
      "Predicted Label: neutral\n"
     ]
    }
   ],
   "source": [
    "def predict_partisanship(text_message):\n",
    "    cleaned_message = preprocess_text(text_message)\n",
    "    \n",
    "    vectorized_message = vectorizer.transform([cleaned_message])\n",
    "    \n",
    "    prediction = model.predict(vectorized_message)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "new_text_1 = \"Higher costs are bad\"\n",
    "prediction_1 = predict_partisanship(new_text_1)\n",
    "print(f\"\\nMessage: '{new_text_1}'\")\n",
    "print(f\"Predicted Label: {prediction_1}\")\n",
    "\n",
    "new_text_2 = \"The committee will hold a hearing tomorrow at 10 AM to discuss the new transportation bill.\"\n",
    "prediction_2 = predict_partisanship(new_text_2)\n",
    "print(f\"\\nMessage: '{new_text_2}'\")\n",
    "print(f\"Predicted Label: {prediction_2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
